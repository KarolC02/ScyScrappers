{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76bc1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"skyscraper-scraper\")\n",
    "\n",
    "def get_country_from_city(city_name):\n",
    "    try:\n",
    "        location = geolocator.geocode(city_name, exactly_one=True, timeout=10)\n",
    "        if location and location.address:\n",
    "            for part in location.address.split(\",\")[::-1]:\n",
    "                if part.strip().isalpha():\n",
    "                    return part.strip()\n",
    "    except GeocoderTimedOut:\n",
    "        time.sleep(1)\n",
    "        return get_country_from_city(city_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5c2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1695a1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_constructed.csv\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=construction&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_under_construction.csv\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=proposed&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_proposed.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_constructed.csv\"\n",
    ")\n",
    "\n",
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=construction&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_under_construction.csv\"\n",
    ")\n",
    "\n",
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=proposed&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_proposed.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_country_cache = {\n",
    "    # Already provided\n",
    "    \"Jeddah\": \"Saudi Arabia\",\n",
    "    \"Dubai\": \"United Arab Emirates\",\n",
    "    \"Shanghai\": \"China\",\n",
    "    \"Dongguan\": \"China\",\n",
    "    \"New York City\": \"United States\",\n",
    "    \"Abidjan\": \"Ivory Coast\",\n",
    "    \"Ras al Khaimah\": \"United Arab Emirates\",\n",
    "    \"Bangkok\": \"Thailand\",\n",
    "    \"Miami\": \"United States\",\n",
    "    \"Austin\": \"United States\",\n",
    "    \"New York\": \"United States\",\n",
    "    \"Toronto\": \"Canada\",\n",
    "    \"Oklahoma City\": \"United States\",\n",
    "\n",
    "    # Newly identified\n",
    "    \"Mecca\": \"Saudi Arabia\",\n",
    "    \"Seoul\": \"South Korea\",\n",
    "    \"St. Petersburg\": \"Russia\",\n",
    "    \"Ho Chi Minh City\": \"Vietnam\",\n",
    "    \"Busan\": \"South Korea\",\n",
    "    \"Ningbo\": \"China\",\n",
    "    \"Nanning\": \"China\",\n",
    "    \"Abu Dhabi\": \"United Arab Emirates\",\n",
    "    \"Istanbul\": \"Turkey\",\n",
    "    \"Xi‚Äôan\": \"China\",\n",
    "    \"Kaohsiung\": \"Taiwan\",\n",
    "    \"Goyang\": \"South Korea\",\n",
    "    \"Durban\": \"South Africa\",\n",
    "    \"Colombo\": \"Sri Lanka\",\n",
    "    \"Watamu\": \"Kenya\",\n",
    "    \"Beijing\": \"China\",\n",
    "    \"Riyadh\": \"Saudi Arabia\",\n",
    "    \"Moscow\": \"Russia\",\n",
    "    \"Philadelphia\": \"United States\",\n",
    "    \"Los Angeles\": \"United States\",\n",
    "    \"Chicago\": \"United States\",\n",
    "    \"Osaka\" : \"Japan\",\n",
    "    \"Bogota\" : \"Colombai\"\n",
    "}\n",
    "\n",
    "city_country_cache[\"Osaka\"] = \"Japan\"\n",
    "city_country_cache[\"Johannesburg\"] = \"South Africa\"\n",
    "city_country_cache[\"London\"] = \"United Kingdom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_country_cache[\"Toronto\"] = \"Canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff197334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"city-country-mapper\")\n",
    "\n",
    "US_STATES = {\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\",\n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\",\n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n",
    "    \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\",\n",
    "    \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\",\n",
    "    \"Wisconsin\", \"Wyoming\"\n",
    "}\n",
    "\n",
    "\n",
    "# ‚úÖ Add this cache dictionary\n",
    "\n",
    "\n",
    "def get_country(city):\n",
    "    if city in city_country_cache:\n",
    "        return city_country_cache[city]\n",
    "\n",
    "    try:\n",
    "        location = geolocator.geocode(city, exactly_one=True, language=\"en\")\n",
    "        if location and location.address:\n",
    "            address_parts = [part.strip() for part in location.address.split(\",\")]\n",
    "            # Check if any known US state is in the address\n",
    "            for part in reversed(address_parts):\n",
    "                if part in US_STATES:\n",
    "                    city_country_cache[city] = \"United States\"\n",
    "                    return \"United States\"\n",
    "                elif part.isalpha():\n",
    "                    city_country_cache[city] = part\n",
    "                    return part\n",
    "    except GeocoderTimedOut:\n",
    "        print(\"EXCEPT\")\n",
    "        time.sleep(1)\n",
    "        return get_country(city)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    city_country_cache[city] = None\n",
    "    return None\n",
    "\n",
    "\n",
    "def add_country_column(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"üåç Resolving countries for {len(df)} rows...\")\n",
    "\n",
    "    countries = []\n",
    "    for i, city in enumerate(df['City']):\n",
    "        country = get_country(city)\n",
    "        countries.append(country)\n",
    "        print(f\"{i+1}/{len(df)}: {city} ‚Üí {country}\")\n",
    "\n",
    "    df.insert(df.columns.get_loc(\"City\") + 1, \"Country\", countries)\n",
    "\n",
    "    output_path = os.path.splitext(csv_path)[0] + \"_with_countries.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ae7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraping complete. Data saved to tallest_buildings.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def extract_height_parts(p_tag):\n",
    "    try:\n",
    "        text = p_tag.get_text().strip().replace(\"\\xa0\", \" \")  # e.g., \"828 m / 2,717 ft\"\n",
    "        parts = text.split('/')\n",
    "        meters = parts[0].strip().replace(\" m\", \"\").replace(\",\", \"\")\n",
    "        feet = parts[1].strip().replace(\" ft\", \"\").replace(\",\", \"\")\n",
    "        return int(meters), int(feet)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to parse height: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def scrape_skyscrapers():\n",
    "    URL = \"https://www.skyscrapercenter.com/buildings\"\n",
    "    response = requests.get(URL, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    table_rows = soup.find_all(\"tr\")\n",
    "\n",
    "    buildings = []\n",
    "    for row in table_rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 9:\n",
    "            continue  # skip non-data rows\n",
    "\n",
    "        try:\n",
    "            name = cols[1].find(\"a\").text.strip()\n",
    "            city = cols[2].find(\"a\").text.strip()\n",
    "            completion = cols[4].text.strip()\n",
    "\n",
    "            height_p = cols[5].find(\"p\")\n",
    "            height_m, height_ft = extract_height_parts(height_p)\n",
    "\n",
    "            floors = cols[6].text.strip()\n",
    "            material = cols[7].text.strip()\n",
    "            function = cols[8].text.strip()\n",
    "\n",
    "            buildings.append({\n",
    "                \"Name\": name,\n",
    "                \"City\": city,\n",
    "                \"Completion Year\": completion,\n",
    "                \"Height (m)\": height_m,\n",
    "                \"Height (ft)\": height_ft,\n",
    "                \"Floors\": floors,\n",
    "                \"Material\": material,\n",
    "                \"Function\": function,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Skipping row due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(buildings)\n",
    "    df.to_csv(\"100_tallest_buildings.csv\", index=False)\n",
    "    print(\"‚úÖ Scraping complete. Data saved to tallest_buildings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"city-country-mapper\")\n",
    "\n",
    "# ‚úÖ Add this cache dictionary\n",
    "city_country_cache = {}\n",
    "\n",
    "def get_country(city):\n",
    "    if city in city_country_cache:\n",
    "        return city_country_cache[city]\n",
    "    \n",
    "    try:\n",
    "        location = geolocator.geocode(city, exactly_one=True, language=\"en\")\n",
    "        if location and location.address:\n",
    "            for part in location.address.split(\",\")[::-1]:\n",
    "                if part.strip().isalpha():\n",
    "                    country = part.strip()\n",
    "                    city_country_cache[city] = country\n",
    "                    return country\n",
    "    except GeocoderTimedOut:\n",
    "        time.sleep(1)\n",
    "        return get_country(city)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    city_country_cache[city] = None\n",
    "    return None\n",
    "\n",
    "def add_country_column(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"üåç Resolving countries for {len(df)} rows...\")\n",
    "\n",
    "    countries = []\n",
    "    for i, city in enumerate(df['City']):\n",
    "        country = get_country(city)\n",
    "        countries.append(country)\n",
    "        print(f\"{i+1}/{len(df)}: {city} ‚Üí {country}\")\n",
    "\n",
    "    df.insert(df.columns.get_loc(\"City\") + 1, \"Country\", countries)\n",
    "\n",
    "    output_path = os.path.splitext(csv_path)[0] + \"_with_countries.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7351b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_constructed.csv\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=construction&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_under_construction.csv\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=proposed&material=all&function=all&location=world&year=2025\n",
      "‚úÖ Saved to 100_tallest_proposed.csv\n"
     ]
    }
   ],
   "source": [
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_constructed.csv\"\n",
    ")\n",
    "\n",
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=construction&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_under_construction.csv\"\n",
    ")\n",
    "\n",
    "scrape_skyscrapers(\n",
    "    \"https://www.skyscrapercenter.com/buildings?status=proposed&material=all&function=all&location=world&year=2025\",\n",
    "    \"100_tallest_proposed.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b87992bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Scraping for year 1890...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1890\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1890.csv\n",
      "üîé Scraping for year 1900...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1900\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1900.csv\n",
      "üîé Scraping for year 1910...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1910\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1910.csv\n",
      "üîé Scraping for year 1920...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1920\n",
      "‚ö†Ô∏è Failed to parse height: list index out of range\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1920.csv\n",
      "üîé Scraping for year 1930...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1930\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1930.csv\n",
      "üîé Scraping for year 1940...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1940\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1940.csv\n",
      "üîé Scraping for year 1950...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1950\n",
      "‚ö†Ô∏è Failed to parse height: list index out of range\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1950.csv\n",
      "üîé Scraping for year 1960...\n",
      "üîé Scraping from: https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year=1960\n",
      "‚ö†Ô∏è Failed to parse height: list index out of range\n",
      "‚úÖ Saved to 100_tallest_constructed_world_1960.csv\n"
     ]
    }
   ],
   "source": [
    "for year in range(1890, 1970, 10):\n",
    "    url = f\"https://www.skyscrapercenter.com/buildings?status=completed&material=all&function=all&location=world&year={year}\"\n",
    "    output_filename = f\"100_tallest_constructed_world_{year}.csv\"\n",
    "    print(f\"üîé Scraping for year {year}...\")\n",
    "    scrape_skyscrapers(url, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Resolving countries for 100_tallest_constructed_world_1890.csv...\n",
      "üåç Resolving countries for 100 rows...\n",
      "1/100: Turin ‚Üí Italy\n",
      "2/100: Ulm ‚Üí Germany\n",
      "3/100: Cologne ‚Üí Germany\n",
      "4/100: Rouen ‚Üí France\n",
      "5/100: Hamburg ‚Üí Germany\n",
      "6/100: Strasbourg ‚Üí France\n",
      "7/100: Vienna ‚Üí Austria\n",
      "8/100: Hamburg ‚Üí Germany\n",
      "9/100: Vatican City ‚Üí None\n",
      "10/100: Hamburg ‚Üí Germany\n",
      "11/100: Landshut ‚Üí Germany\n",
      "12/100: Tallinn ‚Üí Estonia\n",
      "13/100: Riga ‚Üí Latvia\n",
      "14/100: Antwerp ‚Üí Belgium\n",
      "15/100: Salisbury ‚Üí England\n",
      "16/100: St. Petersburg ‚Üí Russia\n",
      "17/100: Hamburg ‚Üí Germany\n",
      "18/100: Florence ‚Üí Italy\n",
      "19/100: Utrecht ‚Üí Netherlands\n",
      "20/100: London ‚Üí United Kingdom\n",
      "21/100: Springfield (IL) ‚Üí United States\n",
      "22/100: Graz ‚Üí Austria\n",
      "23/100: Delft ‚Üí Netherlands\n",
      "24/100: Milan ‚Üí Italy\n",
      "25/100: Tallinn ‚Üí Estonia\n",
      "26/100: Dortmund ‚Üí Germany\n",
      "27/100: Dortmund ‚Üí Germany\n",
      "28/100: New York City ‚Üí United States\n",
      "29/100: London ‚Üí United Kingdom\n",
      "30/100: St. Petersburg ‚Üí Russia\n",
      "31/100: Amersfoort ‚Üí Netherlands\n",
      "32/100: Chicago ‚Üí United States\n",
      "33/100: Vienna ‚Üí Austria\n",
      "34/100: Pittsburgh ‚Üí United States\n",
      "35/100: Breda ‚Üí Netherlands\n",
      "36/100: Groningen ‚Üí Netherlands\n",
      "37/100: Doesburg ‚Üí Netherlands\n",
      "38/100: Brussels ‚Üí Belgium\n",
      "39/100: Austin ‚Üí United States\n",
      "40/100: New York City ‚Üí United States\n",
      "41/100: Berlin ‚Üí Germany\n",
      "42/100: The Hague ‚Üí Netherlands\n",
      "43/100: New York City ‚Üí United States\n",
      "44/100: The Hague ‚Üí Netherlands\n",
      "45/100: Louth ‚Üí England\n",
      "46/100: Bristol ‚Üí England\n",
      "47/100: Brugge ‚Üí Belgium\n",
      "48/100: Washington D.C. ‚Üí United States\n",
      "49/100: Hartford ‚Üí United States\n",
      "50/100: Leeuwarden ‚Üí Netherlands\n",
      "51/100: Stockholm ‚Üí Sweden\n",
      "52/100: New York City ‚Üí United States\n",
      "53/100: Steenwijk ‚Üí Netherlands\n",
      "54/100: Amsterdam ‚Üí Netherlands\n",
      "55/100: Rhenen ‚Üí Netherlands\n",
      "56/100: Amsterdam ‚Üí Netherlands\n",
      "57/100: Amsterdam ‚Üí Netherlands\n",
      "58/100: Hengelo ‚Üí Netherlands\n",
      "59/100: Buffalo ‚Üí United States\n",
      "60/100: Des Moines ‚Üí United States\n",
      "61/100: Atlanta ‚Üí United States\n",
      "62/100: Lincoln ‚Üí United States\n",
      "63/100: Buffalo ‚Üí United States\n",
      "64/100: London ‚Üí United Kingdom\n",
      "65/100: Sittard ‚Üí Netherlands\n",
      "66/100: Lansing ‚Üí United States\n",
      "67/100: Haarlem ‚Üí Netherlands\n",
      "68/100: New York City ‚Üí United States\n",
      "69/100: Delft ‚Üí Netherlands\n",
      "70/100: Tilburg ‚Üí Netherlands\n",
      "71/100: New York City ‚Üí United States\n",
      "72/100: Minneapolis ‚Üí United States\n",
      "73/100: Groningen ‚Üí Netherlands\n",
      "74/100: Groningen ‚Üí Netherlands\n",
      "75/100: Charleston, SC ‚Üí United States\n",
      "76/100: Indianapolis ‚Üí United States\n",
      "77/100: Woerden ‚Üí Netherlands\n",
      "78/100: Dubuque ‚Üí United States\n",
      "79/100: Sacramento ‚Üí United States\n",
      "80/100: Cologne ‚Üí Germany\n",
      "81/100: Haarlem ‚Üí Netherlands\n",
      "82/100: Zwolle ‚Üí Netherlands\n",
      "83/100: Enkhuizen ‚Üí Netherlands\n",
      "84/100: Boston ‚Üí United States\n",
      "85/100: Buffalo ‚Üí United States\n",
      "86/100: Hilvarenbeek ‚Üí Netherlands\n",
      "87/100: New York City ‚Üí United States\n",
      "88/100: Boston ‚Üí United States\n",
      "89/100: Naarden ‚Üí Netherlands\n",
      "90/100: Agra ‚Üí India\n",
      "91/100: Chicago ‚Üí United States\n",
      "92/100: Stockholm ‚Üí Sweden\n",
      "93/100: Delft ‚Üí Netherlands\n",
      "94/100: Weert ‚Üí Netherlands\n",
      "95/100: Paris ‚Üí France\n",
      "96/100: Syracuse ‚Üí Italy\n",
      "97/100: New York City ‚Üí United States\n",
      "98/100: Rochester ‚Üí United States\n",
      "99/100: Franeker ‚Üí Netherlands\n"
     ]
    }
   ],
   "source": [
    "for year in range(1890, 1970, 10):\n",
    "    filename = f\"100_tallest_constructed_world_{year}.csv\"\n",
    "    print(f\"üåç Resolving countries for {filename}...\")\n",
    "    add_country_column(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2433ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdccac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
